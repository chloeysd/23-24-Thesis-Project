{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Text Cleaning for the Dataset\n",
    "\n",
    "The training dataset used is from the [MBTI Personality Types](https://www.kaggle.com/datasets/datasnaek/mbti-type), which includes social media posts and their corresponding MBTI personality type labels. The text cleaning process, inspired by a [StackOverflow discussion](https://stackoverflow.com/questions/55187374/cleaning-text-with-python-and-re), involves converting text to lowercase, removing punctuation, URLs, and HTML tags, and stripping leading and trailing whitespace.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#define a text cleaner class\n",
    "class TextCleaner:\n",
    "    def clean_text(text):\n",
    "        #convert text to lowercase and remove specific punctuation and symbols\n",
    "        text = re.sub(r\"[-()\\\"#/@;:<>{}+=~|.,?]\", \"\", text.lower())\n",
    "        #replace '|||' with a space\n",
    "        text = re.sub(r'\\|\\|\\|', ' ', text)\n",
    "        #remove URLs and HTML tags\n",
    "        text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "        text = re.sub(r'<.*?>', '', text)\n",
    "        #strip leading and trailing spacesï¼Œref:https://www.w3schools.com/python/ref_string_strip.asp\n",
    "        return text.strip()\n",
    "\n",
    "#read data from the CSV file into a DataFrame\n",
    "data = pd.read_csv('data/mbti_1.csv')\n",
    "#apply the clean_text method from TextCleaner class to the 'posts' column, then store in a new column 'cleaned_posts'\n",
    "data['cleaned_posts'] = data['posts'].apply(TextCleaner.clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset Splitting and Preprocessing (split Function)\n",
    "\n",
    "I use the `split` function to divide the cleaned dataset into training and testing sets, and then perform TF-IDF vectorization on the text data. Additionally, the target labels are encoded using `LabelEncoder`. Once these steps are completed, the data is ready to be fed into machine learning models for training and prediction.\n",
    "\n",
    "This method is inspired by a [Kaggle notebook](https://www.kaggle.com/code/anandu08/psycho-analysis-nlp-fr-enhanced-social-media-con/notebook#Performance-Visualisation) and has been optimized and simplified to improve code readability and execution efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#function to split dataset and preprocess\n",
    "def split(df, size):\n",
    "    #split the dataset into training and testing sets with stratification on 'type'\n",
    "    train_data, test_data = train_test_split(df, test_size=size, random_state=0, stratify=df['type'])\n",
    "\n",
    "    #initialize the TF-IDF vectorizer with a max of 5000 features and English stopwords \n",
    "    vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "    #fit and transform the training data into a TF-IDF matrix\n",
    "    train_post = vectorizer.fit_transform(train_data['cleaned_posts']).toarray()\n",
    "    #transform the test data using the same vectorizer\n",
    "    test_post = vectorizer.transform(test_data['cleaned_posts']).toarray()\n",
    "\n",
    "    #initialize the LabelEncoder\n",
    "    target_encoder = LabelEncoder()\n",
    "    #encode the target labels for the training data\n",
    "    train_target = target_encoder.fit_transform(train_data['type'])\n",
    "    #encode the target labels for the test data\n",
    "    test_target = target_encoder.fit_transform(test_data['type'])\n",
    "\n",
    "    #return the processed data and the encoding/vectorization tools\n",
    "    return train_post, test_post, train_target, test_target, target_encoder, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Function for Running All the Models\n",
    "\n",
    "I utilized the `model` function to train and evaluate several machine learning models, including KNN, Logistic Regression, Linear SVC, Multinomial Naive Bayes, Decision Tree, and Random Forest. Each of these models was trained on the training dataset and then evaluated on the test dataset to compare their performance.\n",
    "\n",
    "The function returns the accuracy and F1 scores for each model, which allows us to assess which model is most effective for predicting MBTI types. The results indicate that the **Linear Support Vector Classifier** achieved the highest accuracy and F1 scores, suggesting it might be more suitable for this task compared to the other models.\n",
    "\n",
    "This process was inspired by and optimized from a [Kaggle notebook](https://www.kaggle.com/code/anandu08/psycho-analysis-nlp-fr-enhanced-social-media-con/notebook#Performance-Visualisation), which provides a comprehensive analysis of various models' performance on a similar task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running KNN\n",
      "Running Logistic Regression\n",
      "Running Linear SVC\n",
      "Running Multinomial Naive Bayes\n",
      "Running Decision Tree Classifier\n",
      "Running Random Forest\n",
      "                             Models  Test accuracy\n",
      "0                               KNN       0.368300\n",
      "1               Logistic Regression       0.621902\n",
      "2  Linear Support Vector Classifier       0.662248\n",
      "3           Multinomial Naive Bayes       0.378674\n",
      "4          Decision Tree Classifier       0.508934\n",
      "5          Random Forest Classifier       0.448415\n",
      "                             Models  Test F1 Score\n",
      "0                               KNN       0.275026\n",
      "1               Logistic Regression       0.340786\n",
      "2  Linear Support Vector Classifier       0.465726\n",
      "3           Multinomial Naive Bayes       0.112725\n",
      "4          Decision Tree Classifier       0.315774\n",
      "5          Random Forest Classifier       0.162310\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "\n",
    "def model(X_train, X_test, y_train, y_test, count, target_encoder):\n",
    "    #dictionary to store accuracy for each model\n",
    "    models_accuracy = {}\n",
    "    #dictionary to store classification report for each model\n",
    "    report = {}\n",
    "    #dictionary to store F1 scores for each model\n",
    "    f1_scores = {}  \n",
    "    \n",
    "    # KNN\n",
    "    print(\"Running KNN\")\n",
    "    neigh = KNeighborsClassifier()\n",
    "    neigh.fit(X_train, y_train)\n",
    "    #showing accuracy and f1_scores\n",
    "    models_accuracy['KNN'] = accuracy_score(y_test, neigh.predict(X_test))\n",
    "    f1_scores['KNN'] = f1_score(y_test, neigh.predict(X_test), average='macro')\n",
    "    report['KNN'] = classification_report(y_test, neigh.predict(X_test), zero_division=0)\n",
    "    \n",
    "    # Logistic Regression\n",
    "    print(\"Running Logistic Regression\")\n",
    "    model_log = LogisticRegression(max_iter=3000, C=0.5, n_jobs=-1)\n",
    "    model_log.fit(X_train, y_train)\n",
    "    models_accuracy['Logistic Regression'] = accuracy_score(y_test, model_log.predict(X_test))\n",
    "    f1_scores['Logistic Regression'] = f1_score(y_test, model_log.predict(X_test), average='macro')\n",
    "    report['Logistic Regression'] = classification_report(y_test, model_log.predict(X_test), zero_division=0)\n",
    "    \n",
    "    # Linear SVC\n",
    "    print(\"Running Linear SVC\")\n",
    "    model_linear_SVC = LinearSVC(C=0.1)\n",
    "    model_linear_SVC.fit(X_train, y_train)\n",
    "    models_accuracy['Linear Support Vector Classifier'] = accuracy_score(y_test, model_linear_SVC.predict(X_test))\n",
    "    f1_scores['Linear Support Vector Classifier'] = f1_score(y_test, model_linear_SVC.predict(X_test), average='macro')\n",
    "    report['Linear Support Vector Classifier'] = classification_report(y_test, model_linear_SVC.predict(X_test), zero_division=0)\n",
    "\n",
    "    # Multinomial Naive Bayes\n",
    "    print(\"Running Multinomial Naive Bayes\")\n",
    "    model_multinomial_nb = MultinomialNB()\n",
    "    model_multinomial_nb.fit(X_train, y_train)\n",
    "    models_accuracy['Multinomial Naive Bayes'] = accuracy_score(y_test, model_multinomial_nb.predict(X_test))\n",
    "    f1_scores['Multinomial Naive Bayes'] = f1_score(y_test, model_multinomial_nb.predict(X_test), average='macro')\n",
    "    report['Multinomial Naive Bayes'] = classification_report(y_test, model_multinomial_nb.predict(X_test), zero_division=0)\n",
    "    \n",
    "    # Decision Tree Classifier\n",
    "    print(\"Running Decision Tree Classifier\")\n",
    "    model_tree = DecisionTreeClassifier(max_depth=14)\n",
    "    model_tree.fit(X_train, y_train)\n",
    "    models_accuracy['Decision Tree Classifier'] = accuracy_score(y_test, model_tree.predict(X_test))\n",
    "    f1_scores['Decision Tree Classifier'] = f1_score(y_test, model_tree.predict(X_test), average='macro')\n",
    "    report['Decision Tree Classifier'] = classification_report(y_test, model_tree.predict(X_test), zero_division=0)\n",
    "\n",
    "    # Random Forest\n",
    "    print(\"Running Random Forest\")\n",
    "    model_forest = RandomForestClassifier(max_depth=10)\n",
    "    model_forest.fit(X_train, y_train)\n",
    "    models_accuracy['Random Forest Classifier'] = accuracy_score(y_test, model_forest.predict(X_test))\n",
    "    f1_scores['Random Forest Classifier'] = f1_score(y_test, model_forest.predict(X_test), average='macro')\n",
    "    report['Random Forest Classifier'] = classification_report(y_test, model_forest.predict(X_test), zero_division=0)\n",
    "    \n",
    "    #convert accuracy and F1 score dictionaries to DataFrames\n",
    "    accuracy_under = pd.DataFrame(models_accuracy.items(), columns=['Models', 'Test accuracy'])\n",
    "    f1_under = pd.DataFrame(f1_scores.items(), columns=['Models', 'Test F1 Score'])\n",
    "    \n",
    "    #return the accuracy DataFrame, classification reports, and F1 score DataFrame\n",
    "    return accuracy_under, report, f1_under\n",
    "\n",
    "#split the dataset and get training and testing data\n",
    "X_train, X_test, y_train, y_test, target_encoder, vectorizer = split(data, 0.2)\n",
    "#run the model function to get accuracy and F1 scores for different models\n",
    "accuracy_under, report, f1_under = model(X_train, X_test, y_train, y_test, len(target_encoder.classes_), target_encoder)\n",
    "print(accuracy_under)\n",
    "print(f1_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Testing the Linear SVC Model\n",
    "\n",
    "In this step, the Linear SVC model is tested using a list of example sentences. After training the model on the dataset, the `predict_mbti` function is used to clean, vectorize, and predict the MBTI type for each sentence. This process helps evaluate the model's performance on new, unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence: I love spending time alone and reflecting on my thoughts.\n",
      "Predicted MBTI Type: INFP\n",
      "Input Sentence: I'm always looking for new ways to connect with others.\n",
      "Predicted MBTI Type: INFJ\n",
      "Input Sentence: Logic and reasoning are the most important aspects of any decision.\n",
      "Predicted MBTI Type: INTJ\n",
      "Input Sentence: I enjoy exploring new places and meeting new people.\n",
      "Predicted MBTI Type: ENFP\n",
      "Input Sentence: Planning ahead is key to staying organized and efficient.\n",
      "Predicted MBTI Type: INTJ\n",
      "Input Sentence: I often find myself daydreaming about future possibilities.\n",
      "Predicted MBTI Type: INFP\n"
     ]
    }
   ],
   "source": [
    "#split the dataset and get training and testing data\n",
    "X_train, X_test, y_train, y_test, target_encoder, vectorizer = split(data, 0.2)\n",
    "#train the Linear SVC model\n",
    "model_linear_SVC = LinearSVC(C=0.1)\n",
    "model_linear_SVC.fit(X_train, y_train)\n",
    "\n",
    "#list of test sentences for prediction\n",
    "test_sentences = [\n",
    "    \"I love spending time alone and reflecting on my thoughts.\",\n",
    "    \"I'm always looking for new ways to connect with others.\",\n",
    "    \"Logic and reasoning are the most important aspects of any decision.\",\n",
    "    \"I enjoy exploring new places and meeting new people.\",\n",
    "    \"Planning ahead is key to staying organized and efficient.\",\n",
    "    \"I often find myself daydreaming about future possibilities.\"]\n",
    "\n",
    "def predict_mbti(sentence, vectorizer, model, target_encoder):\n",
    "    #clean the input sentence\n",
    "    cleaned_sentence = TextCleaner.clean_text(sentence)\n",
    "    #vectorize the cleaned sentence\n",
    "    vectorized_sentence = vectorizer.transform([cleaned_sentence]).toarray()\n",
    "    #predict the MBTI type\n",
    "    prediction = model.predict(vectorized_sentence)\n",
    "    #convert the prediction to the original MBTI type\n",
    "    return target_encoder.inverse_transform(prediction)[0]\n",
    "\n",
    "#predict MBTI type for each sentence in the list\n",
    "for sentence in test_sentences:\n",
    "    predicted_mbti = predict_mbti(sentence, vectorizer, model_linear_SVC, target_encoder)\n",
    "    print(f\"Input Sentence: {sentence}\")\n",
    "    print(f\"Predicted MBTI Type: {predicted_mbti}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Saving the Trained Model and Tools\n",
    "\n",
    "The trained Linear SVC model, along with the TF-IDF vectorizer and label encoder, are saved to files using `joblib`. The code for saving these objects is based on the usage described in the [Joblib Documentation: `joblib.dump`](https://joblib.readthedocs.io/en/latest/generated/joblib.dump.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "#save the trained Linear SVC model to a file\n",
    "model_filename = 'mbti_linear_svc_model.pkl'\n",
    "joblib.dump(model_linear_SVC, model_filename)\n",
    "\n",
    "#save the TF-IDF vectorizer used for text transformation\n",
    "vectorizer_filename = 'tfidf_vectorizer.pkl'\n",
    "joblib.dump(vectorizer, vectorizer_filename)\n",
    "\n",
    "#save the label encoder for converting predictions back to MBTI types\n",
    "encoder_filename = 'label_encoder.pkl'\n",
    "joblib.dump(target_encoder, encoder_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
